{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NisargBhatt73/Deep-Learning/blob/master/DecisionTree\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz0ou1jYQyda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        \"\"\"Find the best split for a node.\n",
        "        \"Best\" means that the average impurity of the two children, weighted by their\n",
        "        population, is the smallest possible. Additionally it must be less than the\n",
        "        impurity of the current node.\n",
        "        To find the best split, we loop through all the features, and consider all the\n",
        "        midpoints between adjacent training samples as possible thresholds. We compute\n",
        "        the Gini impurity of the split generated by that particular feature/threshold\n",
        "        pair, and return the pair with smallest impurity.\n",
        "        Returns:\n",
        "            best_idx: Index of the feature for best split, or None if no split is found.\n",
        "            best_thr: Threshold to use for the split, or None if no split is found.\n",
        "        \"\"\"\n",
        "        # Need at least two elements to split a node.\n",
        "        m = y.size\n",
        "        if m <= 1:\n",
        "            return None, None\n",
        "\n",
        "        # Count of each class in the current node.\n",
        "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
        "\n",
        "        # Gini of current node.\n",
        "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
        "        best_idx, best_thr = None, None\n",
        "\n",
        "        # Loop through all features.\n",
        "        for idx in range(self.n_features_):\n",
        "            # Sort data along selected feature.\n",
        "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
        "\n",
        "            # We could actually split the node according to each feature/threshold pair\n",
        "            # and count the resulting population for each class in the children, but\n",
        "            # instead we compute them in an iterative fashion, making this for loop\n",
        "            # linear rather than quadratic.\n",
        "            num_left = [0] * self.n_classes_\n",
        "            num_right = num_parent.copy()\n",
        "            for i in range(1, m):  # possible split positions\n",
        "                c = classes[i - 1]\n",
        "                num_left[c] += 1\n",
        "                num_right[c] -= 1\n",
        "                gini_left = 1.0 - sum(\n",
        "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
        "                )\n",
        "                gini_right = 1.0 - sum(\n",
        "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
        "                )\n",
        "\n",
        "                # The Gini impurity of a split is the weighted average of the Gini\n",
        "                # impurity of the children.\n",
        "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
        "\n",
        "                # The following condition is to make sure we don't try to split two\n",
        "                # points with identical values for that feature, as it is impossible\n",
        "                # (both have to end up on the same side of a split).\n",
        "                if thresholds[i] == thresholds[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_idx = idx\n",
        "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
        "\n",
        "        return best_idx, best_thr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3xJ_mP0RA3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxmIBA0VRGnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Node:\n",
        "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
        "        self.gini = gini\n",
        "        self.num_samples = num_samples\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.predicted_class = predicted_class\n",
        "        self.feature_index = 0\n",
        "        self.threshold = 0\n",
        "        self.left = None\n",
        "        self.right = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIElteo8RThM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Build decision tree classifier.\"\"\"\n",
        "        self.n_classes_ = len(set(y))  # classes are assumed to go from 0 to n-1\n",
        "        self.n_features_ = X.shape[1]\n",
        "        self.tree_ = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        \"\"\"Build a decision tree by recursively finding the best split.\"\"\"\n",
        "        # Population for each class in current node. The predicted class is the one with\n",
        "        # largest population.\n",
        "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
        "        predicted_class = np.argmax(num_samples_per_class)\n",
        "        node = Node(\n",
        "            gini=self._gini(y),\n",
        "            num_samples=y.size,\n",
        "            num_samples_per_class=num_samples_per_class,\n",
        "            predicted_class=predicted_class,\n",
        "        )\n",
        "\n",
        "        # Split recursively until maximum depth is reached.\n",
        "        if depth < self.max_depth:\n",
        "            idx, thr = self._best_split(X, y)\n",
        "            if idx is not None:\n",
        "                indices_left = X[:, idx] < thr\n",
        "                X_left, y_left = X[indices_left], y[indices_left]\n",
        "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
        "                node.feature_index = idx\n",
        "                node.threshold = thr\n",
        "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
        "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
        "        return node"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AvO4fsuKZXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def predict(self, X):\n",
        "        return [self._predict(inputs) for inputs in X]\n",
        "\n",
        "    def _predict(self, inputs):\n",
        "        \"\"\"Predict class for a single sample.\"\"\"\n",
        "        node = self.tree_\n",
        "        while node.left:\n",
        "            if inputs[node.feature_index] < node.threshold:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node.predicted_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLv2F8pCKcoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}